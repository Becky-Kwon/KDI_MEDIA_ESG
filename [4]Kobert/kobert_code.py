# -*- coding: utf-8 -*-
"""kobert_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pXiwB7Vqyo8xqI39Y7gwe-JcEk0cGr0P

# KoBERT finetuning
"""

!pip install ipywidgets  # for vscode
!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master

import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import gluonnlp as nlp
import numpy as np
from tqdm.notebook import tqdm

from kobert import get_tokenizer
from kobert import get_pytorch_kobert_model

from transformers import AdamW
from transformers.optimization import get_cosine_schedule_with_warmup

## CPU
#device = torch.device("cpu")

## GPU
device = torch.device("cuda:0")

bertmodel, vocab = get_pytorch_kobert_model(cachedir=".cache")

"""# 데이터 불러오기"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df_train = pd.read_csv('/content/train.csv')
df_test = pd.read_csv('/content/test.csv')
df_pred = pd.read_csv('/content/pred.csv')
#df_pred = pd.read_csv('/content/esg_2012_2017_dataset_ESG_Filtered.csv', )

df_train['label'] = df_train['label'].astype('int')
df_test['label'] = df_test['label'].astype('int')
df_pred['label'] = df_pred['label'].astype('int')

df_pred

df_train

df_test

df_train.to_csv('/content/train.tsv', sep = '\t', index = False)
df_test.to_csv('/content/test.tsv', sep = '\t', index = False)
df_pred.to_csv('/content/pred.tsv', sep = '\t', index = False)

aa = pd.read_csv('/content/train.tsv', sep="\t")

aa[2710:]

dataset_train = nlp.data.TSVDataset('/content/train.tsv', field_indices=[1,2], num_discard_samples=1)
dataset_test = nlp.data.TSVDataset("/content/test.tsv", field_indices=[1,2], num_discard_samples=1)
dataset_pred = nlp.data.TSVDataset("/content/pred.tsv", field_indices=[1,2], num_discard_samples=1)

dataset_train[:5]

dataset_test[:5]

dataset_pred[:5]

len(dataset_pred)

len(dataset_train)

len(dataset_test)

tokenizer = get_tokenizer()
tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)

class BERTDataset(Dataset):
    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,
                 pad, pair):
        transform = nlp.data.BERTSentenceTransform(
            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)

        self.sentences = [transform([i[sent_idx]]) for i in dataset]
        self.labels = [np.int32(i[label_idx]) for i in dataset]

    def __getitem__(self, i):
        return (self.sentences[i] + (self.labels[i], ))

    def __len__(self):
        return (len(self.labels))

## Setting parameters
max_len = 64
batch_size = 64
warmup_ratio = 0.1
num_epochs = 5
max_grad_norm = 1
log_interval = 200
learning_rate =  5e-5

data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)
data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)
data_pred = BERTDataset(dataset_pred, 0, 1, tok, max_len, True, False)

train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)
test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)
pred_dataloader = torch.utils.data.DataLoader(data_pred, batch_size=batch_size, num_workers=5)

class BERTClassifier(nn.Module):
    def __init__(self,
                 bert,
                 hidden_size = 768,
                 num_classes=2,
                 dr_rate=None,
                 params=None):
        super(BERTClassifier, self).__init__()
        self.bert = bert
        self.dr_rate = dr_rate

        self.classifier = nn.Linear(hidden_size , num_classes)
        if dr_rate:
            self.dropout = nn.Dropout(p=dr_rate)

    def gen_attention_mask(self, token_ids, valid_length):
        attention_mask = torch.zeros_like(token_ids)
        for i, v in enumerate(valid_length):
            attention_mask[i][:v] = 1
        return attention_mask.float()

    def forward(self, token_ids, valid_length, segment_ids):
        attention_mask = self.gen_attention_mask(token_ids, valid_length)

        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))
        if self.dr_rate:
            out = self.dropout(pooler)
        return self.classifier(out)

model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)

# Prepare optimizer and schedule (linear warmup and decay)
no_decay = ['bias', 'LayerNorm.weight']
optimizer_grouped_parameters = [
    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},
    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}
]

optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)
loss_fn = nn.CrossEntropyLoss()

t_total = len(train_dataloader) * num_epochs
warmup_step = int(t_total * warmup_ratio)

scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)

def calc_accuracy(X,Y):
    max_vals, max_indices = torch.max(X, 1)
    #print(max_vals)
    #print(max_indices)
    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]
    return train_acc

max_vals, max_indices = torch.max(out, 1)
print(max_vals)
print(max_indices.tolist())
train_acc = (max_indices == label).sum().data.cpu().numpy()/max_indices.size()[0]

label_list = label.tolist()
type(label_list)

print(accuracy_score(label_list, max_indices.tolist()))

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score

labels = [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]	# 실제 labels
guesses = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0]	# 에측된 결과

print(accuracy_score(labels, guesses))	# 0.3
print(recall_score(labels, guesses))	# 0.42
print(precision_score(labels, guesses))	# 0.5
print(f1_score(labels, guesses))	# 0.46

for e in range(num_epochs+5):
  pred_result = []
  train_acc = 0.0
  test_acc = 0.0
  test_pre = 0.0
  test_recall = 0.0
  test_f1score = 0.0
  test_recall_negative = 0.0
  model.train()
  for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):
      optimizer.zero_grad()
      token_ids = token_ids.long().to(device)
      segment_ids = segment_ids.long().to(device)
      valid_length= valid_length
      label = label.long().to(device)
      out = model(token_ids, valid_length, segment_ids)
      loss = loss_fn(out, label)
      loss.backward()
      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
      optimizer.step()
      scheduler.step()  # Update learning rate schedule
      train_acc += calc_accuracy(out, label)
      if batch_id % log_interval == 0:
          print("epoch {} batch id {} loss {} train acc {}".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))
  print("epoch {} train acc {}".format(e+1, train_acc / (batch_id+1)))
  model.eval()
  for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):
      token_ids = token_ids.long().to(device)
      segment_ids = segment_ids.long().to(device)
      valid_length= valid_length
      label = label.long().to(device)
      out = model(token_ids, valid_length, segment_ids)
      max_vals_test, max_indices_test = torch.max(out, 1)
      test_acc += calc_accuracy(out, label)
      test_pre += precision_score(label.tolist(), max_indices_test.tolist())
      test_recall += recall_score(label.tolist(), max_indices_test.tolist())
      test_recall_negative += recall_score(label.tolist(), max_indices_test.tolist(), pos_label = 0)
      test_f1score += f1_score(label.tolist(), max_indices_test.tolist())

      test_result_batch = max_indices_test.tolist()
      pred_result.extend(test_result_batch)
  print("epoch {} test acc {}".format(e+1, test_acc / (batch_id+1)))
  print("epoch {} test precision {}".format(e+1, test_pre / (batch_id+1)))
  print("epoch {} test recall {}".format(e+1, test_recall / (batch_id+1)))
  print("epoch {} test recall for negative {}".format(e+1, test_recall_negative / (batch_id+1)))
  print("epoch {} test f1score {}".format(e+1, test_f1score/ (batch_id+1)))

batch_id

df_test['pred_result'] = pred_result

len(pred_result)

df_test2  =  df_test[['document','label','pred_result']]

df_train['pred_result'] = -1

df_train2 = df_train[['document','label','pred_result']]

df_with_labels = pd.concat([df_train2, df_test2]).reset_index(drop=True)

df_with_labels.to_csv('df_with_labels_14170.csv', encoding= 'utf-8-sig', index = False)

df_pred_pred = pd.read_csv('/pred_with_result.csv')
df_pred_pred.tail()

df_pred_pred['pred_result'] = df_pred_pred['label']
df_pred_pred['label'] = -1
df_pred_pred2 = df_pred_pred[['document','label','pred_result']]

df_everything = pd.concat([df_with_labels, df_pred_pred2]).reset_index(drop = False)

df_everything.tail()

df_everything.to_csv('df_train_test_pred_75161.csv', encoding= 'utf-8-sig', index = False)

"""## Recall for Negative"""

for e in range(num_epochs+5):
    train_acc = 0.0
    test_acc = 0.0
    test_pre = 0.0
    test_recall = 0.0
    test_f1score = 0.0
    model.train()
    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):
        optimizer.zero_grad()
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        loss = loss_fn(out, label)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()
        scheduler.step()  # Update learning rate schedule
        train_acc += calc_accuracy(out, label)
        if batch_id % log_interval == 0:
            print("epoch {} batch id {} loss {} train acc {}".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))
    print("epoch {} train acc {}".format(e+1, train_acc / (batch_id+1)))
    model.eval()
    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        max_vals_test, max_indices_test = torch.max(out, 1)
        test_acc += calc_accuracy(out, label)
        test_pre += precision_score(label.tolist(), max_indices_test.tolist())
        test_recall += recall_score(label.tolist(), max_indices_test.tolist(), pos_label = 0)
        test_f1score += f1_score(label.tolist(), max_indices_test.tolist())
    print("epoch {} test acc {}".format(e+1, test_acc / (batch_id+1)))
    print("epoch {} test precision {}".format(e+1, test_pre / (batch_id+1)))
    print("epoch {} test recall {}".format(e+1, test_recall / (batch_id+1)))
    print("epoch {} test f1score {}".format(e+1, test_f1score/ (batch_id+1)))

for e in range(num_epochs):
    id_check = []
    pred_result = []
    train_acc = 0.0
    test_acc = 0.0
    test_pre = 0.0
    test_recall = 0.0
    test_f1score = 0.0
    model.train()
    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):
        optimizer.zero_grad()
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        loss = loss_fn(out, label)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)
        optimizer.step()
        scheduler.step()  # Update learning rate schedule
        train_acc += calc_accuracy(out, label)
        if batch_id % log_interval == 0:
            print("epoch {} batch id {} loss {} train acc {}".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))
    print("epoch {} train acc {}".format(e+1, train_acc / (batch_id+1)))
    model.eval()
    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):
        token_ids = token_ids.long().to(device)
        segment_ids = segment_ids.long().to(device)
        valid_length= valid_length
        label = label.long().to(device)
        out = model(token_ids, valid_length, segment_ids)
        max_vals_test, max_indices_test = torch.max(out, 1)
        test_acc += calc_accuracy(out, label)
        test_pre += precision_score(label.tolist(), max_indices_test.tolist())
        test_recall += recall_score(label.tolist(), max_indices_test.tolist())
        test_f1score += f1_score(label.tolist(), max_indices_test.tolist())
    print("epoch {} test acc {}".format(e+1, test_acc / (batch_id+1)))
    print("epoch {} test precision {}".format(e+1, test_pre / (batch_id+1)))
    print("epoch {} test recall {}".format(e+1, test_recall / (batch_id+1)))
    print("epoch {} test f1score {}".format(e+1, test_f1score/ (batch_id+1)))

token_ids[:,0]

id_check = []
pred_result = []

pred_dataloader

pred_dataloader = torch.utils.data.DataLoader(data_pred, batch_size=1, num_workers=5)

for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(pred_dataloader), total=len(pred_dataloader)):
  token_ids = token_ids.long().to(device)
  segment_ids = segment_ids.long().to(device)
  valid_length= valid_length
  #label = label.long().to(device)
  out = model(token_ids, valid_length, segment_ids)
  max_vals_test, max_indices_test = torch.max(out, 1)

  result_batch = max_indices_test.tolist()
  id_list = segment_ids.tolist()

  pred_result.extend(result_batch)
  id_check.extend(id_list)

len(pred_result)

df_pred['label'] = pred_result

calc_accuracy(out, label)

df_pred.to_csv('/content/pred_with_result_new.csv', encoding = 'utf-8-sig', index = False)

"""## 마지막 2012~2017 예측하기"""

df_pred2 = pd.read_csv('/content/drive/MyDrive/esg_2012_2017_dataset_ESG_Filtered.csv', )
df_pred_6 = df_pred2[['title','url']]
df_pred_6.loc[:,'id'] = list(range(len(df_pred_6)))
df_pred_6.loc[:,'label'] = 0
df_pred_6.columns = ['document','url','id','label']
df_pred_6_new = df_pred_6[['id','document','label']]

df_pred_6_new.to_csv('/content/drive/MyDrive/esg_2012_2017.tsv', sep = '\t',index =False)

df_pred_6_new

dataset6 = nlp.data.TSVDataset('/content/drive/MyDrive/esg_2012_2017.tsv', field_indices=[1,2], num_discard_samples=1)
data_6 = BERTDataset(dataset6, 0, 1, tok, max_len, True, False)
dataloader6 = torch.utils.data.DataLoader(data_6, batch_size=batch_size, num_workers=5)

result_6 = []
id_6 = []

for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(dataloader6), total=len(dataloader6)):
  token_ids = token_ids.long().to(device)
  segment_ids = segment_ids.long().to(device)
  valid_length= valid_length
  #label = label.long().to(device)
  out = model(token_ids, valid_length, segment_ids)
  max_vals_test, max_indices_test = torch.max(out, 1)

  result_batch = max_indices_test.tolist()
  id_list = segment_ids.tolist()

  result_6.extend(result_batch)
  id_6.extend(id_list)

len(result_6)

df_pred_6_new['label'] = 'NA'
df_pred_6_new['pred_result'] = result_6

df_pred_6_new.to_csv('/content/drive/MyDrive/2012_2017_pred_result.csv', encoding = 'utf-8-sig', index = False)